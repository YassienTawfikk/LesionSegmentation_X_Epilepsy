{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13403907,"sourceType":"datasetVersion","datasetId":8506405}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# SynthSeg Organs & FCD Lesion Segmentation","metadata":{}},{"cell_type":"markdown","source":"## Subject & Sequence Info","metadata":{}},{"cell_type":"code","source":"subject_number = 1              # Subject index (1 â†’ 150)\nsequence_type = \"T1\"          # Image sequence: \"T1\" or \"FLAIR\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T03:05:32.982765Z","iopub.execute_input":"2025-10-23T03:05:32.983285Z","iopub.status.idle":"2025-10-23T03:05:32.987121Z","shell.execute_reply.started":"2025-10-23T03:05:32.983247Z","shell.execute_reply":"2025-10-23T03:05:32.986371Z"}},"outputs":[],"execution_count":44},{"cell_type":"markdown","source":"## Required Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\n\nimport numpy as np\nimport pandas as pd\nimport nibabel as nib\nfrom nilearn.image import resample_img","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-23T02:46:48.903193Z","iopub.execute_input":"2025-10-23T02:46:48.903891Z","iopub.status.idle":"2025-10-23T02:46:48.907352Z","shell.execute_reply.started":"2025-10-23T02:46:48.903870Z","shell.execute_reply":"2025-10-23T02:46:48.906504Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## Directory Utilities","metadata":{}},{"cell_type":"code","source":"def delete_directory(dir_path, self_delete=False):\n    \"\"\"\n    Deletes all contents of a directory. Optionally deletes the directory itself.\n\n    Args:\n        dir_path (str): Path to the directory to clear.\n        self_delete (bool): If True, deletes the directory itself after clearing contents.\n    \"\"\"\n    if not os.path.exists(dir_path):\n        print(f\"Path does not exist: {dir_path}\")\n        return\n\n    for item in os.listdir(dir_path):\n        item_path = os.path.join(dir_path, item)\n        try:\n            if os.path.isfile(item_path) or os.path.islink(item_path):\n                os.unlink(item_path)\n            elif os.path.isdir(item_path):\n                shutil.rmtree(item_path)\n        except Exception as e:\n            print(f\"Failed to delete {item_path}: {e}\")\n\n    if self_delete:\n        try:\n            shutil.rmtree(dir_path)\n        except Exception as e:\n            print(f\"Failed to delete directory itself: {e}\")\n\n\ndef clear_kaggle_working():\n    \"\"\"Clears the '/kaggle/working' directory.\"\"\"\n    kaggle_working_path = \"/kaggle/working\"\n    delete_directory(kaggle_working_path)\n\n\ndef print_folder_structure(start_path, indent=\"\"):\n    \"\"\"\n    Recursively prints the directory structure in a tree-like format.\n\n    Args:\n        start_path (str): Directory path to start printing from.\n        indent (str): Indentation for nested levels.\n    \"\"\"\n    if not os.path.exists(start_path):\n        print(f\"Error: Path '{start_path}' does not exist.\")\n        return\n\n    if not os.path.isdir(start_path):\n        print(f\"Error: Path '{start_path}' is not a directory.\")\n        return\n\n    entries = sorted(os.listdir(start_path))  # Sort entries for consistent output\n\n    for i, entry in enumerate(entries):\n        entry_path = os.path.join(start_path, entry)\n        is_last = i == len(entries) - 1\n\n        prefix = \"â””â”€â”€ \" if is_last else \"â”œâ”€â”€ \"\n        print(f\"{indent}{prefix}{entry}\")\n\n        if os.path.isdir(entry_path):\n            next_indent = indent + (\"    \" if is_last else \"â”‚   \")\n            print_folder_structure(entry_path, next_indent)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T02:46:51.133013Z","iopub.execute_input":"2025-10-23T02:46:51.133299Z","iopub.status.idle":"2025-10-23T02:46:51.141589Z","shell.execute_reply.started":"2025-10-23T02:46:51.133279Z","shell.execute_reply":"2025-10-23T02:46:51.140863Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"delete_directory(\"/kaggle/working/output\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T02:51:14.030052Z","iopub.execute_input":"2025-10-23T02:51:14.030777Z","iopub.status.idle":"2025-10-23T02:51:14.038522Z","shell.execute_reply.started":"2025-10-23T02:51:14.030754Z","shell.execute_reply":"2025-10-23T02:51:14.037756Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"## Setup Kaggle Working Directory","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/\n\n# Clone the SynthSeg repository\n!git clone https://github.com/GabrieleLozupone/SynthSeg-TF2.15-Dataset.git synthseg_modern\n\n\n!mkdir -p output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T02:49:55.184740Z","iopub.execute_input":"2025-10-23T02:49:55.184990Z","iopub.status.idle":"2025-10-23T02:50:00.118309Z","shell.execute_reply.started":"2025-10-23T02:49:55.184974Z","shell.execute_reply":"2025-10-23T02:50:00.117174Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"/kaggle/working\nCloning into 'synthseg_modern'...\nremote: Enumerating objects: 2374, done.\u001b[K\nremote: Counting objects: 100% (692/692), done.\u001b[K\nremote: Compressing objects: 100% (161/161), done.\u001b[K\nremote: Total 2374 (delta 617), reused 531 (delta 531), pack-reused 1682 (from 3)\u001b[K\nReceiving objects: 100% (2374/2374), 120.58 MiB | 43.97 MiB/s, done.\nResolving deltas: 100% (1533/1533), done.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"## Install Repository Dependencies","metadata":{}},{"cell_type":"code","source":"# Navigate to the repository root\n%cd /kaggle/working/synthseg_modern\n\n# Install Python dependencies from requirements.txt\n!pip install -r requirements.txt\n\nprint(\"\\nâœ”ï¸ All dependencies installed successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T02:08:06.009880Z","iopub.execute_input":"2025-10-23T02:08:06.010171Z","iopub.status.idle":"2025-10-23T02:11:47.748106Z","shell.execute_reply.started":"2025-10-23T02:08:06.010148Z","shell.execute_reply":"2025-10-23T02:11:47.747284Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"/kaggle/working/SynthSeg-Modern\nLooking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\nCollecting absl-py==2.1.0 (from -r requirements.txt (line 1))\n  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (1.6.3)\nCollecting cachetools==5.4.0 (from -r requirements.txt (line 3))\n  Downloading cachetools-5.4.0-py3-none-any.whl.metadata (5.3 kB)\nCollecting certifi==2024.7.4 (from -r requirements.txt (line 4))\n  Downloading certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\nCollecting charset-normalizer==3.3.2 (from -r requirements.txt (line 5))\n  Downloading charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\nCollecting flatbuffers==24.3.25 (from -r requirements.txt (line 6))\n  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\nRequirement already satisfied: gast==0.6.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (0.6.0)\nCollecting google-auth==2.33.0 (from -r requirements.txt (line 8))\n  Downloading google_auth-2.33.0-py2.py3-none-any.whl.metadata (4.7 kB)\nCollecting google-auth-oauthlib==1.2.1 (from -r requirements.txt (line 9))\n  Downloading google_auth_oauthlib-1.2.1-py2.py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: google-pasta==0.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (0.2.0)\nCollecting grpcio==1.65.4 (from -r requirements.txt (line 11))\n  Downloading grpcio-1.65.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\nCollecting h5py==3.11.0 (from -r requirements.txt (line 12))\n  Downloading h5py-3.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\nCollecting idna==3.7 (from -r requirements.txt (line 13))\n  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\nCollecting keras==2.15.0 (from -r requirements.txt (line 14))\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: libclang==18.1.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (18.1.1)\nCollecting Markdown==3.6 (from -r requirements.txt (line 16))\n  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\nCollecting MarkupSafe==2.1.5 (from -r requirements.txt (line 17))\n  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\nCollecting ml-dtypes==0.2.0 (from -r requirements.txt (line 18))\n  Downloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nCollecting nibabel==5.2.1 (from -r requirements.txt (line 19))\n  Downloading nibabel-5.2.1-py3-none-any.whl.metadata (8.8 kB)\nRequirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 20)) (1.26.4)\nCollecting nvidia-cublas-cu12==12.2.5.6 (from -r requirements.txt (line 21))\n  Downloading https://pypi.nvidia.com/nvidia-cublas-cu12/nvidia_cublas_cu12-12.2.5.6-py3-none-manylinux1_x86_64.whl (417.8 MB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m417.8/417.8 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.2.142 (from -r requirements.txt (line 22))\n  Downloading https://pypi.nvidia.com/nvidia-cuda-cupti-cu12/nvidia_cuda_cupti_cu12-12.2.142-py3-none-manylinux1_x86_64.whl (13.9 MB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m123.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-nvcc-cu12==12.2.140 (from -r requirements.txt (line 23))\n  Downloading https://pypi.nvidia.com/nvidia-cuda-nvcc-cu12/nvidia_cuda_nvcc_cu12-12.2.140-py3-none-manylinux1_x86_64.whl (21.3 MB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m151.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.2.140 (from -r requirements.txt (line 24))\n  Downloading https://pypi.nvidia.com/nvidia-cuda-nvrtc-cu12/nvidia_cuda_nvrtc_cu12-12.2.140-py3-none-manylinux1_x86_64.whl (23.4 MB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.4/23.4 MB\u001b[0m \u001b[31m161.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.2.140 (from -r requirements.txt (line 25))\n  Downloading https://pypi.nvidia.com/nvidia-cuda-runtime-cu12/nvidia_cuda_runtime_cu12-12.2.140-py3-none-manylinux1_x86_64.whl (845 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m845.8/845.8 kB\u001b[0m \u001b[31m198.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.4.25 (from -r requirements.txt (line 26))\n  Downloading https://pypi.nvidia.com/nvidia-cudnn-cu12/nvidia_cudnn_cu12-8.9.4.25-py3-none-manylinux1_x86_64.whl (720.1 MB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m720.1/720.1 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cufft-cu12==11.0.8.103 (from -r requirements.txt (line 27))\n  Downloading https://pypi.nvidia.com/nvidia-cufft-cu12/nvidia_cufft_cu12-11.0.8.103-py3-none-manylinux1_x86_64.whl (98.6 MB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m98.6/98.6 MB\u001b[0m \u001b[31m117.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-curand-cu12==10.3.3.141 (from -r requirements.txt (line 28))\n  Downloading https://pypi.nvidia.com/nvidia-curand-cu12/nvidia_curand_cu12-10.3.3.141-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m136.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusolver-cu12==11.5.2.141 (from -r requirements.txt (line 29))\n  Downloading https://pypi.nvidia.com/nvidia-cusolver-cu12/nvidia_cusolver_cu12-11.5.2.141-py3-none-manylinux1_x86_64.whl (124.9 MB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.9/124.9 MB\u001b[0m \u001b[31m107.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.2.141 (from -r requirements.txt (line 30))\n  Downloading https://pypi.nvidia.com/nvidia-cusparse-cu12/nvidia_cusparse_cu12-12.1.2.141-py3-none-manylinux1_x86_64.whl (195.3 MB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m195.3/195.3 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nccl-cu12==2.16.5 (from -r requirements.txt (line 31))\n  Downloading nvidia_nccl_cu12-2.16.5-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvjitlink-cu12==12.2.140 (from -r requirements.txt (line 32))\n  Downloading https://pypi.nvidia.com/nvidia-nvjitlink-cu12/nvidia_nvjitlink_cu12-12.2.140-py3-none-manylinux1_x86_64.whl (20.2 MB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m145.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting oauthlib==3.2.2 (from -r requirements.txt (line 33))\n  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\nCollecting opt-einsum==3.3.0 (from -r requirements.txt (line 34))\n  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\nCollecting packaging==24.1 (from -r requirements.txt (line 35))\n  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\nCollecting protobuf==4.25.4 (from -r requirements.txt (line 36))\n  Downloading protobuf-4.25.4-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\nCollecting pyasn1==0.6.0 (from -r requirements.txt (line 37))\n  Downloading pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\nCollecting pyasn1_modules==0.4.0 (from -r requirements.txt (line 38))\n  Downloading pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\nCollecting requests==2.32.3 (from -r requirements.txt (line 39))\n  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\nRequirement already satisfied: requests-oauthlib==2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 40)) (2.0.0)\nCollecting rsa==4.9 (from -r requirements.txt (line 41))\n  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\nCollecting scipy==1.14.0 (from -r requirements.txt (line 42))\n  Downloading scipy-1.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting six==1.16.0 (from -r requirements.txt (line 43))\n  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\nCollecting tensorboard==2.15.2 (from -r requirements.txt (line 44))\n  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: tensorboard-data-server==0.7.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 45)) (0.7.2)\nCollecting tensorflow==2.15.0 (from -r requirements.txt (line 46))\n  Downloading tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\nCollecting tensorflow-estimator==2.15.0 (from -r requirements.txt (line 47))\n  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: tensorflow-io-gcs-filesystem==0.37.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 48)) (0.37.1)\nCollecting tensorrt==8.6.1.post1 (from -r requirements.txt (line 50))\n  Downloading https://pypi.nvidia.com/tensorrt/tensorrt-8.6.1.post1.tar.gz (18 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting tensorrt-bindings==8.6.1 (from -r requirements.txt (line 51))\n  Downloading https://pypi.nvidia.com/tensorrt-bindings/tensorrt_bindings-8.6.1-cp311-none-manylinux_2_17_x86_64.whl (980 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m980.8/980.8 kB\u001b[0m \u001b[31m195.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting tensorrt-libs==8.6.1 (from -r requirements.txt (line 52))\n  Downloading https://pypi.nvidia.com/tensorrt-libs/tensorrt_libs-8.6.1-py2.py3-none-manylinux_2_17_x86_64.whl (824.8 MB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m824.8/824.8 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting termcolor==2.4.0 (from -r requirements.txt (line 53))\n  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\nCollecting typing_extensions==4.12.2 (from -r requirements.txt (line 54))\n  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\nCollecting urllib3==2.2.2 (from -r requirements.txt (line 55))\n  Downloading urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\nCollecting Werkzeug==3.0.3 (from -r requirements.txt (line 56))\n  Downloading werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\nCollecting wrapt==1.14.1 (from -r requirements.txt (line 57))\n  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse==1.6.3->-r requirements.txt (line 2)) (0.45.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 20)) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 20)) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 20)) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 20)) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 20)) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 20)) (2.4.1)\nRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.15.2->-r requirements.txt (line 44)) (75.2.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy==1.26.4->-r requirements.txt (line 20)) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy==1.26.4->-r requirements.txt (line 20)) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy==1.26.4->-r requirements.txt (line 20)) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy==1.26.4->-r requirements.txt (line 20)) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy==1.26.4->-r requirements.txt (line 20)) (2024.2.0)\nDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cachetools-5.4.0-py3-none-any.whl (9.5 kB)\nDownloading certifi-2024.7.4-py3-none-any.whl (162 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m163.0/163.0 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (140 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m140.3/140.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\nDownloading google_auth-2.33.0-py2.py3-none-any.whl (200 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_auth_oauthlib-1.2.1-py2.py3-none-any.whl (24 kB)\nDownloading grpcio-1.65.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading h5py-3.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading Markdown-3.6-py3-none-any.whl (105 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\nDownloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nibabel-5.2.1-py3-none-any.whl (3.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.16.5-py3-none-manylinux1_x86_64.whl (188.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading protobuf-4.25.4-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m181.2/181.2 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rsa-4.9-py3-none-any.whl (34 kB)\nDownloading scipy-1.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.1/41.1 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading six-1.16.0-py2.py3-none-any.whl (11 kB)\nDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m475.3/475.3 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\nDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\nDownloading urllib3-2.2.2-py3-none-any.whl (121 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.4/121.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m227.3/227.3 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: tensorrt\n  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for tensorrt: filename=tensorrt-8.6.1.post1-py2.py3-none-any.whl size=17285 sha256=11d95d13119e7c65a3c8de637b361e9a223929c59c09fbf42ea0cf3f1ca6ec65\n  Stored in directory: /root/.cache/pip/wheels/ea/d1/b3/fdd44fb93f123590a5e00b837a92ba33d8b4787e52258fe27e\nSuccessfully built tensorrt\nInstalling collected packages: tensorrt-bindings, flatbuffers, wrapt, urllib3, typing_extensions, termcolor, tensorrt, tensorflow-estimator, six, pyasn1, protobuf, packaging, oauthlib, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-nvcc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, MarkupSafe, Markdown, keras, idna, grpcio, charset-normalizer, certifi, cachetools, absl-py, Werkzeug, rsa, requests, pyasn1_modules, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tensorrt-libs, nvidia-cusolver-cu12, google-auth, google-auth-oauthlib, tensorboard, opt-einsum, ml-dtypes, h5py, tensorflow, scipy, nibabel\n  Attempting uninstall: flatbuffers\n    Found existing installation: flatbuffers 25.2.10\n    Uninstalling flatbuffers-25.2.10:\n      Successfully uninstalled flatbuffers-25.2.10\n  Attempting uninstall: wrapt\n    Found existing installation: wrapt 1.17.2\n    Uninstalling wrapt-1.17.2:\n      Successfully uninstalled wrapt-1.17.2\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 2.5.0\n    Uninstalling urllib3-2.5.0:\n      Successfully uninstalled urllib3-2.5.0\n  Attempting uninstall: typing_extensions\n    Found existing installation: typing_extensions 4.15.0\n    Uninstalling typing_extensions-4.15.0:\n      Successfully uninstalled typing_extensions-4.15.0\n  Attempting uninstall: termcolor\n    Found existing installation: termcolor 3.1.0\n    Uninstalling termcolor-3.1.0:\n      Successfully uninstalled termcolor-3.1.0\n  Attempting uninstall: six\n    Found existing installation: six 1.17.0\n    Uninstalling six-1.17.0:\n      Successfully uninstalled six-1.17.0\n  Attempting uninstall: pyasn1\n    Found existing installation: pyasn1 0.6.1\n    Uninstalling pyasn1-0.6.1:\n      Successfully uninstalled pyasn1-0.6.1\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n  Attempting uninstall: packaging\n    Found existing installation: packaging 25.0\n    Uninstalling packaging-25.0:\n      Successfully uninstalled packaging-25.0\n  Attempting uninstall: oauthlib\n    Found existing installation: oauthlib 3.3.1\n    Uninstalling oauthlib-3.3.1:\n      Successfully uninstalled oauthlib-3.3.1\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvcc-cu12\n    Found existing installation: nvidia-cuda-nvcc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvcc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvcc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: MarkupSafe\n    Found existing installation: MarkupSafe 3.0.2\n    Uninstalling MarkupSafe-3.0.2:\n      Successfully uninstalled MarkupSafe-3.0.2\n  Attempting uninstall: Markdown\n    Found existing installation: Markdown 3.8.2\n    Uninstalling Markdown-3.8.2:\n      Successfully uninstalled Markdown-3.8.2\n  Attempting uninstall: keras\n    Found existing installation: keras 3.8.0\n    Uninstalling keras-3.8.0:\n      Successfully uninstalled keras-3.8.0\n  Attempting uninstall: idna\n    Found existing installation: idna 3.10\n    Uninstalling idna-3.10:\n      Successfully uninstalled idna-3.10\n  Attempting uninstall: grpcio\n    Found existing installation: grpcio 1.75.1\n    Uninstalling grpcio-1.75.1:\n      Successfully uninstalled grpcio-1.75.1\n  Attempting uninstall: charset-normalizer\n    Found existing installation: charset-normalizer 3.4.3\n    Uninstalling charset-normalizer-3.4.3:\n      Successfully uninstalled charset-normalizer-3.4.3\n  Attempting uninstall: certifi\n    Found existing installation: certifi 2025.8.3\n    Uninstalling certifi-2025.8.3:\n      Successfully uninstalled certifi-2025.8.3\n  Attempting uninstall: cachetools\n    Found existing installation: cachetools 5.5.2\n    Uninstalling cachetools-5.5.2:\n      Successfully uninstalled cachetools-5.5.2\n  Attempting uninstall: absl-py\n    Found existing installation: absl-py 1.4.0\n    Uninstalling absl-py-1.4.0:\n      Successfully uninstalled absl-py-1.4.0\n  Attempting uninstall: Werkzeug\n    Found existing installation: Werkzeug 3.1.3\n    Uninstalling Werkzeug-3.1.3:\n      Successfully uninstalled Werkzeug-3.1.3\n  Attempting uninstall: rsa\n    Found existing installation: rsa 4.9.1\n    Uninstalling rsa-4.9.1:\n      Successfully uninstalled rsa-4.9.1\n  Attempting uninstall: requests\n    Found existing installation: requests 2.32.5\n    Uninstalling requests-2.32.5:\n      Successfully uninstalled requests-2.32.5\n  Attempting uninstall: pyasn1_modules\n    Found existing installation: pyasn1_modules 0.4.2\n    Uninstalling pyasn1_modules-0.4.2:\n      Successfully uninstalled pyasn1_modules-0.4.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: google-auth\n    Found existing installation: google-auth 2.40.3\n    Uninstalling google-auth-2.40.3:\n      Successfully uninstalled google-auth-2.40.3\n  Attempting uninstall: google-auth-oauthlib\n    Found existing installation: google-auth-oauthlib 1.2.2\n    Uninstalling google-auth-oauthlib-1.2.2:\n      Successfully uninstalled google-auth-oauthlib-1.2.2\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.18.0\n    Uninstalling tensorboard-2.18.0:\n      Successfully uninstalled tensorboard-2.18.0\n  Attempting uninstall: opt-einsum\n    Found existing installation: opt_einsum 3.4.0\n    Uninstalling opt_einsum-3.4.0:\n      Successfully uninstalled opt_einsum-3.4.0\n  Attempting uninstall: ml-dtypes\n    Found existing installation: ml-dtypes 0.4.1\n    Uninstalling ml-dtypes-0.4.1:\n      Successfully uninstalled ml-dtypes-0.4.1\n  Attempting uninstall: h5py\n    Found existing installation: h5py 3.14.0\n    Uninstalling h5py-3.14.0:\n      Successfully uninstalled h5py-3.14.0\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.18.0\n    Uninstalling tensorflow-2.18.0:\n      Successfully uninstalled tensorflow-2.18.0\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.15.3\n    Uninstalling scipy-1.15.3:\n      Successfully uninstalled scipy-1.15.3\n  Attempting uninstall: nibabel\n    Found existing installation: nibabel 5.3.2\n    Uninstalling nibabel-5.3.2:\n      Successfully uninstalled nibabel-5.3.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.14.0 which is incompatible.\npydantic-core 2.37.2 requires typing-extensions>=4.14.1, but you have typing-extensions 4.12.2 which is incompatible.\nsigstore-models 0.0.5 requires typing-extensions>=4.14.1, but you have typing-extensions 4.12.2 which is incompatible.\npydantic 2.12.0a1 requires typing-extensions>=4.14.1, but you have typing-extensions 4.12.2 which is incompatible.\ndatasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 4.25.4 which is incompatible.\ngoogle-adk 1.14.1 requires requests<3.0.0,>=2.32.4, but you have requests 2.32.3 which is incompatible.\ngoogle-cloud-bigtable 2.32.0 requires google-api-core[grpc]<3.0.0,>=2.17.0, but you have google-api-core 1.34.1 which is incompatible.\npudb 2025.1.1 requires typing-extensions>=4.13, but you have typing-extensions 4.12.2 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.33.0 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\njax 0.5.2 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.2.0 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\ntypeguard 4.4.4 requires typing_extensions>=4.14.0, but you have typing-extensions 4.12.2 which is incompatible.\nbigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\nibis-framework 9.5.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\ntokenizers 0.21.2 requires huggingface-hub<1.0,>=0.16.4, but you have huggingface-hub 1.0.0rc2 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.2.5.6 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.2.142 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.2.140 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.2.140 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 8.9.4.25 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.0.8.103 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.3.141 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.5.2.141 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.1.2.141 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nccl-cu12==2.21.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nccl-cu12 2.16.5 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.2.140 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.1 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\npandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ntf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.15.0 which is incompatible.\ntensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.15.0 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\ntensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.15.0 which is incompatible.\ntensorstore 0.1.74 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\ntransformers 4.53.3 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.0rc2 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\ndb-dtypes 1.4.3 requires packaging>=24.2.0, but you have packaging 24.1 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\njupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\numap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\ndataproc-spark-connect 0.8.3 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\nflask 3.1.1 requires werkzeug>=3.1.0, but you have werkzeug 3.0.3 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed Markdown-3.6 MarkupSafe-2.1.5 Werkzeug-3.0.3 absl-py-2.1.0 cachetools-5.4.0 certifi-2024.7.4 charset-normalizer-3.3.2 flatbuffers-24.3.25 google-auth-2.33.0 google-auth-oauthlib-1.2.1 grpcio-1.65.4 h5py-3.11.0 idna-3.7 keras-2.15.0 ml-dtypes-0.2.0 nibabel-5.2.1 nvidia-cublas-cu12-12.2.5.6 nvidia-cuda-cupti-cu12-12.2.142 nvidia-cuda-nvcc-cu12-12.2.140 nvidia-cuda-nvrtc-cu12-12.2.140 nvidia-cuda-runtime-cu12-12.2.140 nvidia-cudnn-cu12-8.9.4.25 nvidia-cufft-cu12-11.0.8.103 nvidia-curand-cu12-10.3.3.141 nvidia-cusolver-cu12-11.5.2.141 nvidia-cusparse-cu12-12.1.2.141 nvidia-nccl-cu12-2.16.5 nvidia-nvjitlink-cu12-12.2.140 oauthlib-3.2.2 opt-einsum-3.3.0 packaging-24.1 protobuf-4.25.4 pyasn1-0.6.0 pyasn1_modules-0.4.0 requests-2.32.3 rsa-4.9 scipy-1.14.0 six-1.16.0 tensorboard-2.15.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tensorrt-8.6.1.post1 tensorrt-bindings-8.6.1 tensorrt-libs-8.6.1 termcolor-2.4.0 typing_extensions-4.12.2 urllib3-2.2.2 wrapt-1.14.1\n\nğŸ‰ All dependencies are installed and ready.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## SynthSeg Prediction for one subject","metadata":{}},{"cell_type":"markdown","source":"### Organize Output Directory","metadata":{}},{"cell_type":"code","source":"# ==============================\n# --- Configuration Section ---\n# ==============================\nsynthseg_home = \"/kaggle/working/synthseg_modern\"\ndataset_root = \"/kaggle/input/fcd-subject-centric/FCD-Subject-Centric Dataset\"\nbase_output_dir = \"/kaggle/working/output\"\n\nuse_gpu = True  # Flag to enable GPU if available\n\n# ==============================\n# --- Path Setup & Validation ---\n# ==============================\nsequence_type = sequence_type.upper()\nif sequence_type not in [\"T1\", \"FLAIR\"]:\n    raise ValueError(f\"Invalid sequence type '{sequence_type}'. Must be 'T1' or 'FLAIR'.\")\n\nimage_path = os.path.join(\n    dataset_root, f\"sub-{subject_number:05d}\", f\"{sequence_type.lower()}.nii\"\n)\nif not os.path.isfile(image_path):\n    raise FileNotFoundError(f\"Input image not found: {image_path}\")\n\n# --- Output Directory Structure ---\nsubject_output_dir = os.path.join(base_output_dir, f\"sub-{subject_number:05d}\", sequence_type)\nsynthseg_dir = os.path.join(subject_output_dir, \"synthseg\")\nlesions_dir = os.path.join(subject_output_dir, \"lesions\")\nfusion_dir = os.path.join(subject_output_dir, \"fusion\")\n\nfor dir_path in [synthseg_dir, lesions_dir, fusion_dir]:\n    os.makedirs(dir_path, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T03:05:37.629949Z","iopub.execute_input":"2025-10-23T03:05:37.630645Z","iopub.status.idle":"2025-10-23T03:05:37.643963Z","shell.execute_reply.started":"2025-10-23T03:05:37.630623Z","shell.execute_reply":"2025-10-23T03:05:37.643365Z"}},"outputs":[],"execution_count":45},{"cell_type":"markdown","source":"### Model Inference","metadata":{}},{"cell_type":"code","source":"from SynthSeg.predict import predict\n\n# ==============================\n# --- Model & Data Paths ---\n# ==============================\nmodel_path = os.path.join(synthseg_home, \"models\", \"synthseg_1.0.h5\")\ndata_dir = os.path.join(synthseg_home, \"data\", \"labels_classes_priors\")\n\nlabels_segmentation_path = os.path.join(data_dir, \"synthseg_segmentation_labels.npy\")\nnames_segmentation_path = os.path.join(data_dir, \"synthseg_segmentation_names.npy\")\ntopology_classes_path = os.path.join(data_dir, \"synthseg_topological_classes.npy\")\n\n# ==============================\n# --- SynthSeg Output Paths ---\n# ==============================\nsegmentation_path = os.path.join(synthseg_dir, \"segmentation.nii.gz\")\nposteriors_path = os.path.join(synthseg_dir, \"posteriors.nii.gz\")\nresampled_path = os.path.join(synthseg_dir, \"resampled.nii.gz\")\nvolumes_path = os.path.join(synthseg_dir, \"volumes.csv\")\n\n# ==============================\n# --- Prediction Parameters ---\n# ==============================\ncropping_size = 192\ntarget_resolution = 1.0\n\nflip_input = True\nn_neutral_labels = 18\nsmoothing_sigma = 0.5\nkeep_largest_component = True\n\nn_levels = 5\nconv_per_level = 2\nconv_kernel_size = 3\nunet_features = 24\nactivation_function = \"elu\"\nfeature_multiplier = 2\n\ngt_folder = None\nevaluation_labels = None\nlist_incorrect_labels = None\nlist_correct_labels = None\ncompute_distances = False\n\n# ==============================\n# --- Device Setup ---\n# ==============================\nif use_gpu:\n    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n    print(\"\\nUsing GPU (CUDA_VISIBLE_DEVICES=0)\")\nelse:\n    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n    print(\"\\nUsing CPU (CUDA_VISIBLE_DEVICES=-1)\")\n\n# ==============================\n# --- Resample Input Image ---\n# ==============================\nprint(f\"\\nPreparing resampled image at {target_resolution} mm -> {resampled_path}\")\ntry:\n    from nibabel.processing import resample_to_output\n\n    img = nib.load(image_path)\n    resampled_img = resample_to_output(img, voxel_sizes=(target_resolution,) * 3)\n    nib.save(resampled_img, resampled_path)\n    print(f\"âœ”ï¸ Saved resampled image: {resampled_path}\")\n\nexcept Exception as e:\n    print(f\"Warning: resampling failed ({e}). Copying original image instead.\")\n    try:\n        shutil.copy(image_path, resampled_path)\n        print(f\"âœ”ï¸ Copied original image to {resampled_path}\")\n    except Exception as e2:\n        raise RuntimeError(f\"Failed to create resampled file: {e2}\")\n\n# ==============================\n# --- Run SynthSeg Prediction ---\n# ==============================\nprint(\"\\n--- Starting SynthSeg Prediction ---\")\nprint(f\"Subject: sub-{subject_number:05d}\")\nprint(f\"Sequence: {sequence_type}\")\nprint(f\"Input Image: {resampled_path}\")\nprint(f\"Model: {model_path}\")\nprint(f\"Output Directory: {synthseg_dir}\\n\")\n\npredict(\n    path_images=resampled_path,\n    path_segmentations=segmentation_path,\n    path_model=model_path,\n    labels_segmentation=labels_segmentation_path,\n    names_segmentation=names_segmentation_path,\n    path_posteriors=posteriors_path,\n    path_resampled=resampled_path,\n    path_volumes=volumes_path,\n    cropping=cropping_size,\n    target_res=target_resolution,\n    flip=flip_input,\n    topology_classes=topology_classes_path,\n    sigma_smoothing=smoothing_sigma,\n    keep_biggest_component=keep_largest_component,\n    n_levels=n_levels,\n    nb_conv_per_level=conv_per_level,\n    conv_size=conv_kernel_size,\n    unet_feat_count=unet_features,\n    feat_multiplier=feature_multiplier,\n    activation=activation_function,\n    gt_folder=gt_folder,\n    evaluation_labels=evaluation_labels,\n    list_incorrect_labels=list_incorrect_labels,\n    list_correct_labels=list_correct_labels,\n    compute_distances=compute_distances,\n    recompute=True,\n    verbose=True,\n)\n\nprint(\"\\nâœ”ï¸ Prediction complete! Output files:\")\nfor path in [segmentation_path, posteriors_path, resampled_path, volumes_path]:\n    print(f\" - {path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T03:05:38.069107Z","iopub.execute_input":"2025-10-23T03:05:38.069797Z","iopub.status.idle":"2025-10-23T03:06:24.878410Z","shell.execute_reply.started":"2025-10-23T03:05:38.069775Z","shell.execute_reply":"2025-10-23T03:06:24.877599Z"}},"outputs":[{"name":"stdout","text":"\nUsing GPU (CUDA_VISIBLE_DEVICES=0)\n\nPreparing resampled image at 1.0 mm -> /kaggle/working/output/sub-00001/T1/synthseg/resampled.nii.gz\nâœ”ï¸ Saved resampled image: /kaggle/working/output/sub-00001/T1/synthseg/resampled.nii.gz\n\n--- Starting SynthSeg Prediction ---\nSubject: sub-00001\nSequence: T1\nInput Image: /kaggle/working/output/sub-00001/T1/synthseg/resampled.nii.gz\nModel: /kaggle/working/synthseg_modern/models/synthseg_1.0.h5\nOutput Directory: /kaggle/working/output/sub-00001/T1/synthseg\n\npredicting 1/1\n1/1 [==============================] - 1s 683ms/step\n\nâœ”ï¸ Prediction complete! Output files:\n - /kaggle/working/output/sub-00001/T1/synthseg/segmentation.nii.gz\n - /kaggle/working/output/sub-00001/T1/synthseg/posteriors.nii.gz\n - /kaggle/working/output/sub-00001/T1/synthseg/resampled.nii.gz\n - /kaggle/working/output/sub-00001/T1/synthseg/volumes.csv\n","output_type":"stream"}],"execution_count":46},{"cell_type":"markdown","source":"## Lesion Mask Preparation","metadata":{}},{"cell_type":"code","source":"# Define lesion output directory\nlesion_output_dir = os.path.join(subject_output_dir, \"lesions\")\nos.makedirs(lesion_output_dir, exist_ok=True)\n\n# --- Input & Output Paths ---\nlesion_path = os.path.join(dataset_root, f\"sub-{subject_number:05d}\", \"roi.nii\")\nroi_original_path = os.path.join(lesion_output_dir, \"roi_original.nii.gz\")\nresampled_lesion_path = os.path.join(lesion_output_dir, \"roi_resampled.nii.gz\")\n\n# --- Save original lesion mask as .nii.gz ---\nif os.path.isfile(lesion_path):\n    roi_img = nib.load(lesion_path)          # Load original ROI\n    nib.save(roi_img, roi_original_path)     # Save as compressed .nii.gz\nelse:\n    raise FileNotFoundError(\n        f\"Lesion mask not found for subject sub-{subject_number:05d}.\\n\"\n        f\"Expected at: {lesion_path}\\n\"\n        \"This subject may be a Healthy Control (no ROI file present).\"\n    )\n\n# --- Validate SynthSeg resampled reference ---\nif not os.path.isfile(resampled_path):\n    raise FileNotFoundError(\n        f\"Reference image for resampling not found at:\\n{resampled_path}\\n\"\n        \"Ensure SynthSeg finished successfully before running lesion resampling.\"\n    )\n\n# --- Load target space from SynthSeg output ---\ntarget_img = nib.load(resampled_path)\ntarget_shape = target_img.shape\ntarget_affine = target_img.affine\n\n# --- Resample lesion mask ---\nprint(\"\\n--- Starting Lesion Mask Resampling ---\")\nroi_img = nib.load(roi_original_path)\n\nprint(f\"Original lesion mask shape: {roi_img.shape}\")\nprint(f\"Target (SynthSeg) shape: {target_shape}\")\n\ntry:\n    resampled_roi_img = resample_img(\n        img=roi_img,\n        target_affine=target_affine,\n        target_shape=target_shape,\n        interpolation=\"nearest\"  # Preserve binary values\n    )\n    nib.save(resampled_roi_img, resampled_lesion_path)\n\n    print(f\"\\nâœ”ï¸ Lesion mask resampling complete.\")\n    print(f\"Resampled lesion saved at: {resampled_lesion_path}\")\n    print(f\"Resampled lesion shape: {resampled_roi_img.shape}\")\n\nexcept Exception as e:\n    print(f\"\\nResampling failed: {e}\")\n    print(\"Falling back to copying the original lesion mask (unresampled).\")\n    fallback_path = os.path.join(lesion_output_dir, \"roi_original_copy.nii.gz\")\n    try:\n        shutil.copy(roi_original_path, fallback_path)\n        print(f\"âœ”ï¸ Copied original ROI mask to: {fallback_path}\")\n    except Exception as e2:\n        raise RuntimeError(f\"Failed to copy fallback ROI file: {e2}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T03:06:24.879896Z","iopub.execute_input":"2025-10-23T03:06:24.880103Z","iopub.status.idle":"2025-10-23T03:06:26.234206Z","shell.execute_reply.started":"2025-10-23T03:06:24.880088Z","shell.execute_reply":"2025-10-23T03:06:26.233436Z"}},"outputs":[{"name":"stdout","text":"\n--- Starting Lesion Mask Resampling ---\nOriginal lesion mask shape: (160, 256, 256)\nTarget (SynthSeg) shape: (193, 289, 293)\n\nâœ”ï¸ Lesion mask resampling complete.\nResampled lesion saved at: /kaggle/working/output/sub-00001/T1/lesions/roi_resampled.nii.gz\nResampled lesion shape: (193, 289, 293)\n","output_type":"stream"}],"execution_count":47},{"cell_type":"markdown","source":"## Anatomical Brain & FCD Lesion Fusion","metadata":{}},{"cell_type":"code","source":"lesion_class_id = 99  # Label ID for FCD lesion\n\n# --- Paths ---\nfusion_dir = os.path.join(subject_output_dir, \"fusion\")\nfusion_path = os.path.join(fusion_dir, \"final_segmentation_mask.nii.gz\")\nos.makedirs(fusion_dir, exist_ok=True)\n\n# --- SynthSeg segmentation path ---\nsynthseg_segmentation_path = os.path.join(subject_output_dir, \"synthseg\", \"segmentation.nii.gz\")\n\n# --- 1. Load SynthSeg anatomical segmentation ---\nif not os.path.isfile(synthseg_segmentation_path):\n    raise FileNotFoundError(\n        f\"SynthSeg segmentation not found at:\\n{synthseg_segmentation_path}\"\n    )\n\nsynthseg_img = nib.load(synthseg_segmentation_path)\nfused_data = synthseg_img.get_fdata().astype(np.int16)\naffine_synthseg = synthseg_img.affine\n\n# --- 2. Load resampled FCD lesion ROI ---\nif not os.path.isfile(resampled_lesion_path):\n    raise FileNotFoundError(\n        f\"Resampled lesion mask not found at:\\n{resampled_lesion_path}\"\n    )\n\nresampled_lesion_img = nib.load(resampled_lesion_path)\nresampled_roi_data = resampled_lesion_img.get_fdata().astype(np.int8)\n\n# --- 3. Sanity checks ---\nif fused_data.shape != resampled_roi_data.shape:\n    raise ValueError(\n        f\"Shape mismatch: SynthSeg {fused_data.shape} vs lesion {resampled_roi_data.shape}\"\n    )\n\nif not np.allclose(affine_synthseg, resampled_lesion_img.affine, atol=1e-3):\n    print(\"Warning: Affine mismatch detected. Fusion may be spatially misaligned.\")\n\n# --- 4. Fuse lesion into anatomical segmentation ---\nlesion_voxel_indices = np.where(resampled_roi_data == 1)\n\nif lesion_voxel_indices[0].size == 0:\n    print(\"No lesion voxels detected. Fusion will proceed unchanged.\")\nelse:\n    print(f\"Adding {lesion_voxel_indices[0].size:,} lesion voxels (label={lesion_class_id}).\")\n    fused_data[lesion_voxel_indices] = lesion_class_id\n\n# --- 5. Save fused segmentation ---\ntry:\n    # Remove existing file/folder if present\n    if os.path.isdir(fusion_path):\n        shutil.rmtree(fusion_path)\n    elif os.path.exists(fusion_path):\n        os.remove(fusion_path)\n\n    fused_img = nib.Nifti1Image(fused_data, affine_synthseg)\n    nib.save(fused_img, fusion_path)\n\n    print(f\"\\nâœ”ï¸ Fusion complete!\")\n    print(f\"Final fused segmentation saved at: {fusion_path}\")\n    print(f\"Image shape: {fused_data.shape}\")\n\nexcept Exception as e:\n    raise RuntimeError(f\"Failed to save fused segmentation: {e}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T03:06:26.235068Z","iopub.execute_input":"2025-10-23T03:06:26.235418Z","iopub.status.idle":"2025-10-23T03:06:26.888904Z","shell.execute_reply.started":"2025-10-23T03:06:26.235400Z","shell.execute_reply":"2025-10-23T03:06:26.888253Z"}},"outputs":[{"name":"stdout","text":"Adding 2,586 lesion voxels (label=99).\n\nâœ”ï¸ Fusion complete!\nFinal fused segmentation saved at: /kaggle/working/output/sub-00001/T1/fusion/final_segmentation_mask.nii.gz\nImage shape: (193, 289, 293)\n","output_type":"stream"}],"execution_count":48}]}