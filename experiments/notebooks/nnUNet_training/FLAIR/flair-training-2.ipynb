{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13432928,"sourceType":"datasetVersion","datasetId":8526010}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# nnU-Net v2 ‚Äî Training\n```\nINPUT_ROOT\n  ‚îú‚îÄ nnUNet_preprocessed/\n  ‚îÇ   ‚îî‚îÄ Dataset002_BonnFCD/\n  ‚îî‚îÄ nnUNet_raw_data/\n      ‚îî‚îÄ Dataset002_BonnFCD/\n          ‚îú‚îÄ imagesTr\n          ‚îú‚îÄ imagesTs\n          ‚îî‚îÄ labelsTr\n```\n\nWe **copy** RAW (and, if present, PREPROCESSED) into `/kaggle/working` so nnU-Net can train and write results.\nIf you want to **force re-planning**, set `FORCE_REPLAN=True` in the config cell.\n","metadata":{}},{"cell_type":"markdown","source":"#  0) Install & configure \n","metadata":{}},{"cell_type":"code","source":"!pip install nnunetv2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T07:01:12.784594Z","iopub.execute_input":"2025-10-22T07:01:12.784827Z","iopub.status.idle":"2025-10-22T07:02:44.743232Z","shell.execute_reply.started":"2025-10-22T07:01:12.784804Z","shell.execute_reply":"2025-10-22T07:02:44.742285Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os, shutil\nfrom pathlib import Path\n\n# ---- Adjust these if your dataset folder name changes ----\n\nTraining_no = 2   # change based on your training number\nINPUT_ROOT = Path(f\"/kaggle/input/training-flair-{Training_no}\")\nRAW_SRC    = INPUT_ROOT / \"nnUNet_raw_data\"\nPP_SRC     = INPUT_ROOT / \"nnUNet_preprocessed\"\nDATASET_ID = 2\nDATASET_NAME = \"BonnFCD\"\nDATASET_DIR = f\"Dataset{DATASET_ID:03d}_{DATASET_NAME}\"\n\n# Where nnU-Net expects to READ/WRITE\nos.environ[\"nnUNet_raw\"]          = \"/kaggle/working/nnUNet_raw_data\"\nos.environ[\"nnUNet_preprocessed\"] = \"/kaggle/working/nnUNet_preprocessed\"\nos.environ[\"nnUNet_results\"]      = \"/kaggle/working/nnUNet_results\"\n\nRAW_DST = Path(os.environ[\"nnUNet_raw\"])\nPP_DST  = Path(os.environ[\"nnUNet_preprocessed\"])\nRES_DST = Path(os.environ[\"nnUNet_results\"])\n\nFORCE_REPLAN = False   # Set True to ignore provided preprocessed and re-run planning\n\nprint(\"INPUT_ROOT:\", INPUT_ROOT)\nprint(\"RAW_SRC   :\", RAW_SRC / DATASET_DIR)\nprint(\"PP_SRC    :\", PP_SRC / DATASET_DIR)\nprint(\"RAW_DST   :\", RAW_DST)\nprint(\"PP_DST    :\", PP_DST)\nprint(\"RES_DST   :\", RES_DST)\nprint(\"DATASET_DIR:\", DATASET_DIR)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T07:02:44.745135Z","iopub.execute_input":"2025-10-22T07:02:44.745406Z","iopub.status.idle":"2025-10-22T07:02:44.752942Z","shell.execute_reply.started":"2025-10-22T07:02:44.745383Z","shell.execute_reply":"2025-10-22T07:02:44.752266Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 1) Copy RAW (and optionally PREPROCESSED) to working \n","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\nimport shutil, os\n\nRAW_DST.mkdir(parents=True, exist_ok=True)\nPP_DST.mkdir(parents=True, exist_ok=True)\nPath(os.environ[\"nnUNet_results\"]).mkdir(parents=True, exist_ok=True)\n\n# Copy RAW if not already copied\nsrc = ( INPUT_ROOT/ \"nnUNet_raw_data\" / DATASET_DIR)\ndst = RAW_DST / DATASET_DIR\nif not dst.exists():\n    print(\"Copying RAW dataset to working directory...\")\n    shutil.copytree(src, dst)\nelse:\n    print(\"RAW already present at:\", dst)\n\n# Copy PREPROCESSED if available & not forcing replan\npp_src_ds = (INPUT_ROOT / \"nnUNet_preprocessed\" / DATASET_DIR)\npp_dst_ds = PP_DST / DATASET_DIR\nif pp_src_ds.exists() and not FORCE_REPLAN:\n    if not pp_dst_ds.exists():\n        print(\"Copying PREPROCESSED to working directory...\")\n        shutil.copytree(pp_src_ds, pp_dst_ds)\n    else:\n        print(\"PREPROCESSED already present at:\", pp_dst_ds)\nelse:\n    if FORCE_REPLAN:\n        print(\"FORCE_REPLAN=True ‚Üí will run plan_and_preprocess.\")\n    else:\n        print(\"No preprocessed input found; will run plan_and_preprocess.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T07:02:44.753725Z","iopub.execute_input":"2025-10-22T07:02:44.753979Z","iopub.status.idle":"2025-10-22T07:03:33.456856Z","shell.execute_reply.started":"2025-10-22T07:02:44.753958Z","shell.execute_reply":"2025-10-22T07:03:33.456229Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pathlib import Path\nPREP_ROOT = os.environ[\"nnUNet_preprocessed\"]            # should be .../nnUNet_preprocessed\nPP = Path(PREP_ROOT) / \"Dataset002_BonnFCD\"\n\nprint(\"PREP DS:\", PP)\nprint(\"exists:\", PP.exists())\nprint(\"has 3d_fullres plans folder:\", (PP/\"nnUNetPlans_3d_fullres\").exists())\nprint(\"has fingerprint:\", (PP/\"dataset_fingerprint.json\").exists())\n\n# rough count of processed files\ncount_any = sum(1 for _ in PP.rglob(\"*\")) if PP.exists() else 0\nprint(\"preprocessed files (rough count):\", count_any)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T07:03:33.458361Z","iopub.execute_input":"2025-10-22T07:03:33.458605Z","iopub.status.idle":"2025-10-22T07:03:33.468429Z","shell.execute_reply.started":"2025-10-22T07:03:33.458587Z","shell.execute_reply":"2025-10-22T07:03:33.467906Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#  2) Preflight checks (structure + dataset.json + geometry) \n","metadata":{}},{"cell_type":"code","source":"import json, nibabel as nib\n\nDS_ROOT = Path(os.environ[\"nnUNet_raw\"]) / DATASET_DIR\nassert DS_ROOT.exists(), f\"Dataset not found at {DS_ROOT}\"\n\nfor folder in [\"imagesTr\",\"labelsTr\"]:\n    p = DS_ROOT/folder\n    assert p.exists() and p.is_dir(), f\"Missing folder: {p}\"\nimagesTs_exists = (DS_ROOT/\"imagesTs\").exists() and (DS_ROOT/\"imagesTs\").is_dir()\nprint(\"imagesTs:\", \"OK\" if imagesTs_exists else \"Not found (you can still train)\")\n\ndj_path = DS_ROOT/\"dataset.json\"\nassert dj_path.exists(), \"dataset.json is missing!\"\nwith open(dj_path) as f:\n    dj = json.load(f)\n\nprint(\"channel_names:\", dj.get(\"channel_names\"))\nprint(\"labels:\", dj.get(\"labels\"))\nprint(\"file_ending:\", dj.get(\"file_ending\"))\nassert dj.get(\"file_ending\") in [\".nii\", \".nii.gz\"], \"file_ending must be .nii or .nii.gz\"\n\n# Check 1:1 pairing for first 5\nlabels = sorted((DS_ROOT/\"labelsTr\").glob(\"*.nii*\"))\nmissing = []\nfor lbl in labels:\n    stem = lbl.name.replace(\".nii.gz\",\"\").replace(\".nii\",\"\")\n    img0 = DS_ROOT/\"imagesTr\"/f\"{stem}_0000.nii\"\n    img1 = DS_ROOT/\"imagesTr\"/f\"{stem}_0000.nii.gz\"\n    if not img0.exists() and not img1.exists():\n        missing.append(lbl.name)\nassert not missing, f\"Missing images for labels: {missing[:10]}\"\n\n# Geometry spot-check\nchecked = 0\nfor lbl in labels[:5]:\n    stem = lbl.name.replace(\".nii.gz\",\"\").replace(\".nii\",\"\")\n    img_path = DS_ROOT/\"imagesTr\"/f\"{stem}_0000.nii\"\n    if not img_path.exists():\n        img_path = DS_ROOT/\"imagesTr\"/f\"{stem}_0000.nii.gz\"\n    img = nib.load(str(img_path))\n    seg = nib.load(str(lbl))\n    assert img.shape == seg.shape, f\"Shape mismatch for {stem}: {img.shape} vs {seg.shape}\"\n    checked += 1\n\nprint(f\"‚úÖ Preflight OK. Checked {checked} sample pairs.\")\nprint(\"imagesTr count:\", len(list((DS_ROOT/'imagesTr').glob('*.nii*'))))\nprint(\"labelsTr count:\", len(list((DS_ROOT/'labelsTr').glob('*.nii*'))))\nif imagesTs_exists:\n    print(\"imagesTs count:\", len(list((DS_ROOT/'imagesTs').glob('*.nii*'))))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T07:03:33.469109Z","iopub.execute_input":"2025-10-22T07:03:33.469336Z","iopub.status.idle":"2025-10-22T07:03:36.401650Z","shell.execute_reply.started":"2025-10-22T07:03:33.469313Z","shell.execute_reply":"2025-10-22T07:03:36.400996Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#  3) Plan & preprocess (only if needed) \n","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\nneed_replan = FORCE_REPLAN or not (Path(os.environ[\"nnUNet_preprocessed\"]) / DATASET_DIR).exists()\n\nif need_replan:\n    print(\"Running plan_and_preprocess...\")\n    !nnUNetv2_plan_and_preprocess -d \"$(printf '%03d' $DATASET_ID)\" --verify_dataset_integrity\nelse:\n    print(\"Skipping plan_and_preprocess (preprocessed data already present).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T07:03:36.402310Z","iopub.execute_input":"2025-10-22T07:03:36.402733Z","iopub.status.idle":"2025-10-22T07:03:36.556052Z","shell.execute_reply.started":"2025-10-22T07:03:36.402715Z","shell.execute_reply":"2025-10-22T07:03:36.555468Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Make sure every child process sees these (works in Kaggle/Colab)\n%env NNUNET_USE_COMPILE=0\n%env TORCHDYNAMO_DISABLE=1\n%env TORCH_COMPILE_DISABLE=1   # extra belt-and-suspenders","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T07:03:36.556672Z","iopub.execute_input":"2025-10-22T07:03:36.556866Z","iopub.status.idle":"2025-10-22T07:03:36.574847Z","shell.execute_reply.started":"2025-10-22T07:03:36.556852Z","shell.execute_reply":"2025-10-22T07:03:36.574224Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#  4) Train or Resume Training \n","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\nimport shutil, os\n\nsrc_results = INPUT_ROOT / \"nnUNet_results\"\ndst_results = Path(\"/kaggle/working/nnUNet_results\")\n\n# Force-sync (overwrite) the results folder to ensure checkpoints are copied\nif dst_results.exists():\n    print(\"‚ö†Ô∏è Removing old nnUNet_results in working directory to refresh checkpoints...\")\n    shutil.rmtree(dst_results)\nshutil.copytree(src_results, dst_results)\nprint(\"‚úÖ Copied nnUNet_results with checkpoints to working directory.\")\n\nDATASET_ID = 2\nDATASET_NAME = \"BonnFCD\"\ndataset_tag = f\"Dataset{DATASET_ID:03d}_{DATASET_NAME}\"\nFOLD = \"all\"\n\ntrainer_dir = dst_results / dataset_tag / \"nnUNetTrainer__nnUNetPlans__3d_fullres\" / f\"fold_{FOLD}\"\nckpt_dir = trainer_dir\n\nckpt_latest = ckpt_dir / \"checkpoint_latest.pth\"\nckpt_best   = ckpt_dir / \"checkpoint_best.pth\"\n\nprint(\"checkpoint_latest exists:\", ckpt_latest.exists())\nprint(\"checkpoint_best exists:\", ckpt_best.exists())\n\nif ckpt_latest.exists() or ckpt_best.exists():\n    print(\"üü¢ Found checkpoints. Resuming training from fold_all ...\")\n    !nnUNetv2_train \"$(printf '%03d' $DATASET_ID)\" 3d_fullres all -tr nnUNetTrainer --c\nelse:\n    print(\"üîµ No checkpoints found. Starting new training ...\")\n    !nnUNetv2_train \"$(printf '%03d' $DATASET_ID)\" 3d_fullres all -tr nnUNetTrainer\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T07:03:36.575538Z","iopub.execute_input":"2025-10-22T07:03:36.575751Z","execution_failed":"2025-10-22T08:38:59.065Z"}},"outputs":[],"execution_count":null}]}