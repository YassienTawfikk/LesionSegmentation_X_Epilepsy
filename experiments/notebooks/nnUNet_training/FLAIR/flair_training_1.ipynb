{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 13412279,
          "sourceType": "datasetVersion",
          "datasetId": 8512149
        }
      ],
      "dockerImageVersionId": 31154,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "2aa5129b",
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "/kaggle/input/dataset002-bonnfcd-flair/\n",
        "  ├─ nnUNet_preprocessed/\n",
        "  │   └─ Dataset002_BonnFCD/\n",
        "  └─ nnUNet_raw_data/\n",
        "      └─ Dataset002_BonnFCD/\n",
        "          ├─ imagesTr\n",
        "          ├─ imagesTs\n",
        "          └─ labelsTr\n",
        "```\n",
        "\n",
        "We **copy** RAW (and, if present, PREPROCESSED) into `/kaggle/working` so nnU-Net can train and write results.\n",
        "If you want to **force re-planning**, set `FORCE_REPLAN=True` in the config cell.\n"
      ],
      "metadata": {
        "id": "2aa5129b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0) Install & configure"
      ],
      "metadata": {
        "id": "ll5YzkKW1WUT"
      },
      "id": "ll5YzkKW1WUT"
    },
    {
      "id": "6af03c49-91e4-40da-92ec-f0aa4650b169",
      "cell_type": "code",
      "source": [
        "!pip install nnunetv2"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T11:58:56.001633Z",
          "iopub.execute_input": "2025-10-17T11:58:56.002133Z",
          "iopub.status.idle": "2025-10-17T12:00:30.525264Z",
          "shell.execute_reply.started": "2025-10-17T11:58:56.002111Z",
          "shell.execute_reply": "2025-10-17T12:00:30.524491Z"
        },
        "id": "6af03c49-91e4-40da-92ec-f0aa4650b169",
        "outputId": "60c09820-4e45-4a93-d63b-5a5451daf547"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting nnunetv2\n  Downloading nnunetv2-2.6.2.tar.gz (211 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: torch>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2.6.0+cu124)\nCollecting acvl-utils<0.3,>=0.2.3 (from nnunetv2)\n  Downloading acvl_utils-0.2.5.tar.gz (29 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting dynamic-network-architectures<0.5,>=0.4.1 (from nnunetv2)\n  Downloading dynamic_network_architectures-0.4.2.tar.gz (28 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (4.67.1)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (1.15.3)\nCollecting batchgenerators>=0.25.1 (from nnunetv2)\n  Downloading batchgenerators-0.25.1.tar.gz (76 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (1.26.4)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (1.2.2)\nRequirement already satisfied: scikit-image>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.25.2)\nRequirement already satisfied: SimpleITK>=2.2.1 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2.5.2)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2.2.3)\nRequirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.21)\nRequirement already satisfied: tifffile in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2025.6.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2.32.5)\nRequirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (5.3.2)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (3.7.2)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.12.2)\nCollecting imagecodecs (from nnunetv2)\n  Downloading imagecodecs-2025.8.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (20 kB)\nCollecting yacs (from nnunetv2)\n  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\nCollecting batchgeneratorsv2>=0.3.0 (from nnunetv2)\n  Downloading batchgeneratorsv2-0.3.0.tar.gz (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.8.1)\nRequirement already satisfied: blosc2>=3.0.0b1 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (3.6.1)\nCollecting connected-components-3d (from acvl-utils<0.3,>=0.2.3->nnunetv2)\n  Downloading connected_components_3d-3.25.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (32 kB)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2) (11.3.0)\nRequirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2) (1.0.0)\nCollecting unittest2 (from batchgenerators>=0.25.1->nnunetv2)\n  Downloading unittest2-1.1.0-py2.py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: threadpoolctl in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2) (3.6.0)\nCollecting fft-conv-pytorch (from batchgeneratorsv2>=0.3.0->nnunetv2)\n  Downloading fft_conv_pytorch-1.2.0-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: ndindex in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (1.10.0)\nRequirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (1.1.1)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (4.4.0)\nRequirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (2.11.0)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (9.0.0)\nRequirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from dynamic-network-architectures<0.5,>=0.4.1->nnunetv2) (1.0.19)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->nnunetv2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->nnunetv2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->nnunetv2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->nnunetv2) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->nnunetv2) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->nnunetv2) (2.4.1)\nRequirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2) (3.5)\nRequirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2) (2.37.0)\nRequirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2) (25.0)\nRequirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2) (0.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (3.19.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (4.15.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (2025.9.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.1.2->nnunetv2)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.1.2->nnunetv2)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.1.2->nnunetv2)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.1.2->nnunetv2)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.1.2->nnunetv2)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.1.2->nnunetv2)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.1.2->nnunetv2)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.1.2->nnunetv2)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.1.2->nnunetv2)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.1.2->nnunetv2)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.2->nnunetv2) (1.3.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (4.59.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (1.4.8)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (2.9.0.post0)\nRequirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel->nnunetv2) (6.5.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->nnunetv2) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->nnunetv2) (2025.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2) (2025.8.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->nnunetv2) (1.5.2)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from yacs->nnunetv2) (6.0.3)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->nnunetv2) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.2->nnunetv2) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24->nnunetv2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24->nnunetv2) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.24->nnunetv2) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.24->nnunetv2) (2024.2.0)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2) (0.21.0+cu124)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2) (1.0.0rc2)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2) (0.5.3)\nCollecting argparse (from unittest2->batchgenerators>=0.25.1->nnunetv2)\n  Downloading argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\nCollecting traceback2 (from unittest2->batchgenerators>=0.25.1->nnunetv2)\n  Downloading traceback2-1.4.0-py2.py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.24->nnunetv2) (2024.2.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2) (0.28.1)\nRequirement already satisfied: typer-slim in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2) (0.19.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2) (1.1.10)\nCollecting linecache2 (from traceback2->unittest2->batchgenerators>=0.25.1->nnunetv2)\n  Downloading linecache2-1.0.0-py2.py3-none-any.whl.metadata (1000 bytes)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->huggingface_hub->timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2) (4.11.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->huggingface_hub->timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub->timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2) (0.16.0)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer-slim->huggingface_hub->timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2) (8.3.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->huggingface_hub->timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2) (1.3.1)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading imagecodecs-2025.8.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (26.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.4/26.4 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\nDownloading connected_components_3d-3.25.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (4.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading fft_conv_pytorch-1.2.0-py3-none-any.whl (6.8 kB)\nDownloading unittest2-1.1.0-py2.py3-none-any.whl (96 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\nDownloading traceback2-1.4.0-py2.py3-none-any.whl (16 kB)\nDownloading linecache2-1.0.0-py2.py3-none-any.whl (12 kB)\nBuilding wheels for collected packages: nnunetv2, acvl-utils, batchgenerators, batchgeneratorsv2, dynamic-network-architectures\n  Building wheel for nnunetv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for nnunetv2: filename=nnunetv2-2.6.2-py3-none-any.whl size=285890 sha256=7654f1d2684915d2b1426e05c712f188138890fc48f9461aabe3bc698f0b9b1c\n  Stored in directory: /root/.cache/pip/wheels/99/ec/d2/0fb1be0015c40f2dc99535af585e41e876dd2b369039d9385b\n  Building wheel for acvl-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for acvl-utils: filename=acvl_utils-0.2.5-py3-none-any.whl size=27213 sha256=96f97e91029bf9cf4f6b5029d15cb873b51a6f7334d9443c747c8d9f03070b65\n  Stored in directory: /root/.cache/pip/wheels/3f/8c/10/dcba79e0b2d1d463605233cec1fc6cfad47af5230b8985e464\n  Building wheel for batchgenerators (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for batchgenerators: filename=batchgenerators-0.25.1-py3-none-any.whl size=93088 sha256=3772020089936bef616129a5b2737eb7683ae637100227cac58651dd742c3bb3\n  Stored in directory: /root/.cache/pip/wheels/56/11/c7/fadca30e054c602093ffe36ba8a2f0a87dd2f86ac75191d3ed\n  Building wheel for batchgeneratorsv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for batchgeneratorsv2: filename=batchgeneratorsv2-0.3.0-py3-none-any.whl size=65215 sha256=4a7e6220714661bcc1d1a6c4be3db1bb5d9c854920e5a022ac6127ab7d8edf2b\n  Stored in directory: /root/.cache/pip/wheels/c0/c1/8f/94ca60255dbbadf27e1da4885002a6943c95b067b8e2dd39ea\n  Building wheel for dynamic-network-architectures (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for dynamic-network-architectures: filename=dynamic_network_architectures-0.4.2-py3-none-any.whl size=39025 sha256=6e997e0e298b6fe15416d0331ec13301da81827359c3a4f022ac996a3090d2bc\n  Stored in directory: /root/.cache/pip/wheels/07/a9/c3/fcdf69ef4481860db91d0dc2466f63df8c3933262424a23f54\nSuccessfully built nnunetv2 acvl-utils batchgenerators batchgeneratorsv2 dynamic-network-architectures\nInstalling collected packages: linecache2, argparse, yacs, traceback2, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, unittest2, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, fft-conv-pytorch, connected-components-3d, batchgenerators, imagecodecs, dynamic-network-architectures, batchgeneratorsv2, acvl-utils, nnunetv2\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed acvl-utils-0.2.5 argparse-1.4.0 batchgenerators-0.25.1 batchgeneratorsv2-0.3.0 connected-components-3d-3.25.1 dynamic-network-architectures-0.4.2 fft-conv-pytorch-1.2.0 imagecodecs-2025.8.2 linecache2-1.0.0 nnunetv2-2.6.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 traceback2-1.4.0 unittest2-1.1.0 yacs-0.1.8\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "id": "eead4641",
      "cell_type": "code",
      "source": [
        "import os, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# ---- Adjust these if your dataset folder name changes ----\n",
        "INPUT_ROOT = Path(\"/kaggle/input/dataset002-bonnfcd-flair\")\n",
        "RAW_SRC    = INPUT_ROOT / \"nnUNet_raw_data\"\n",
        "PP_SRC     = INPUT_ROOT / \"nnUNet_preprocessed\"\n",
        "DATASET_ID = 2\n",
        "DATASET_NAME = \"BonnFCD\"\n",
        "DATASET_DIR = f\"Dataset{DATASET_ID:03d}_{DATASET_NAME}\"\n",
        "\n",
        "# Where nnU-Net expects to READ/WRITE\n",
        "os.environ[\"nnUNet_raw\"]          = \"/kaggle/working/nnUNet_raw_data\"\n",
        "os.environ[\"nnUNet_preprocessed\"] = \"/kaggle/working/nnUNet_preprocessed\"\n",
        "os.environ[\"nnUNet_results\"]      = \"/kaggle/working/nnUNet_results\"\n",
        "\n",
        "RAW_DST = Path(os.environ[\"nnUNet_raw\"])\n",
        "PP_DST  = Path(os.environ[\"nnUNet_preprocessed\"])\n",
        "RES_DST = Path(os.environ[\"nnUNet_results\"])\n",
        "\n",
        "FORCE_REPLAN = False   # Set True to ignore provided preprocessed and re-run planning\n",
        "\n",
        "print(\"INPUT_ROOT:\", INPUT_ROOT)\n",
        "print(\"RAW_SRC   :\", RAW_SRC / DATASET_DIR)\n",
        "print(\"PP_SRC    :\", PP_SRC / DATASET_DIR)\n",
        "print(\"RAW_DST   :\", RAW_DST)\n",
        "print(\"PP_DST    :\", PP_DST)\n",
        "print(\"RES_DST   :\", RES_DST)\n",
        "print(\"DATASET_DIR:\", DATASET_DIR)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T12:00:30.526581Z",
          "iopub.execute_input": "2025-10-17T12:00:30.526934Z",
          "iopub.status.idle": "2025-10-17T12:00:30.534649Z",
          "shell.execute_reply.started": "2025-10-17T12:00:30.526912Z",
          "shell.execute_reply": "2025-10-17T12:00:30.533735Z"
        },
        "id": "eead4641",
        "outputId": "574db6ab-3704-468c-849d-aeec7bbb6c6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "INPUT_ROOT: /kaggle/input/dataset002-bonnfcd-flair\nRAW_SRC   : /kaggle/input/dataset002-bonnfcd-flair/nnUNet_raw_data/Dataset002_BonnFCD\nPP_SRC    : /kaggle/input/dataset002-bonnfcd-flair/nnUNet_preprocessed/Dataset002_BonnFCD\nRAW_DST   : /kaggle/working/nnUNet_raw_data\nPP_DST    : /kaggle/working/nnUNet_preprocessed\nRES_DST   : /kaggle/working/nnUNet_results\nDATASET_DIR: Dataset002_BonnFCD\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Copy RAW (and optionally PREPROCESSED) to working\n"
      ],
      "metadata": {
        "id": "Ze0Y_0TE1byZ"
      },
      "id": "Ze0Y_0TE1byZ"
    },
    {
      "id": "eb0a0765",
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import shutil, os\n",
        "\n",
        "RAW_DST.mkdir(parents=True, exist_ok=True)\n",
        "PP_DST.mkdir(parents=True, exist_ok=True)\n",
        "Path(os.environ[\"nnUNet_results\"]).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Copy RAW if not already copied\n",
        "src = (Path(\"/kaggle/input/dataset002-bonnfcd-flair\") / \"nnUNet_raw_data\" / DATASET_DIR)\n",
        "dst = RAW_DST / DATASET_DIR\n",
        "if not dst.exists():\n",
        "    print(\"Copying RAW dataset to working directory...\")\n",
        "    shutil.copytree(src, dst)\n",
        "else:\n",
        "    print(\"RAW already present at:\", dst)\n",
        "\n",
        "# Copy PREPROCESSED if available & not forcing replan\n",
        "pp_src_ds = (Path(\"/kaggle/input/dataset002-bonnfcd-flair\") / \"nnUNet_preprocessed\" / DATASET_DIR)\n",
        "pp_dst_ds = PP_DST / DATASET_DIR\n",
        "if pp_src_ds.exists() and not FORCE_REPLAN:\n",
        "    if not pp_dst_ds.exists():\n",
        "        print(\"Copying PREPROCESSED to working directory...\")\n",
        "        shutil.copytree(pp_src_ds, pp_dst_ds)\n",
        "    else:\n",
        "        print(\"PREPROCESSED already present at:\", pp_dst_ds)\n",
        "else:\n",
        "    if FORCE_REPLAN:\n",
        "        print(\"FORCE_REPLAN=True → will run plan_and_preprocess.\")\n",
        "    else:\n",
        "        print(\"No preprocessed input found; will run plan_and_preprocess.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T12:00:30.535500Z",
          "iopub.execute_input": "2025-10-17T12:00:30.535756Z",
          "iopub.status.idle": "2025-10-17T12:01:34.692484Z",
          "shell.execute_reply.started": "2025-10-17T12:00:30.535731Z",
          "shell.execute_reply": "2025-10-17T12:01:34.691622Z"
        },
        "id": "eb0a0765",
        "outputId": "895ffbde-a7b3-4f16-8759-e0f868540034"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Copying RAW dataset to working directory...\nCopying PREPROCESSED to working directory...\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "id": "2f44c08a-2fc4-46c8-9058-ab3be22bd5ac",
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "PREP_ROOT = os.environ[\"nnUNet_preprocessed\"]            # should be .../nnUNet_preprocessed\n",
        "PP = Path(PREP_ROOT) / \"Dataset002_BonnFCD\"\n",
        "\n",
        "print(\"PREP DS:\", PP)\n",
        "print(\"exists:\", PP.exists())\n",
        "print(\"has 3d_fullres plans folder:\", (PP/\"nnUNetPlans_3d_fullres\").exists())\n",
        "print(\"has fingerprint:\", (PP/\"dataset_fingerprint.json\").exists())\n",
        "\n",
        "# rough count of processed files\n",
        "count_any = sum(1 for _ in PP.rglob(\"*\")) if PP.exists() else 0\n",
        "print(\"preprocessed files (rough count):\", count_any)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T12:01:34.694045Z",
          "iopub.execute_input": "2025-10-17T12:01:34.694636Z",
          "iopub.status.idle": "2025-10-17T12:01:34.704882Z",
          "shell.execute_reply.started": "2025-10-17T12:01:34.694615Z",
          "shell.execute_reply": "2025-10-17T12:01:34.704196Z"
        },
        "id": "2f44c08a-2fc4-46c8-9058-ab3be22bd5ac",
        "outputId": "03cf0615-e2fc-4a8f-cb7b-1651834e9b65"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "PREP DS: /kaggle/working/nnUNet_preprocessed/Dataset002_BonnFCD\nexists: True\nhas 3d_fullres plans folder: True\nhas fingerprint: True\npreprocessed files (rough count): 405\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Preflight checks (structure + dataset.json + geometry)"
      ],
      "metadata": {
        "id": "WtpxgtMg1fZp"
      },
      "id": "WtpxgtMg1fZp"
    },
    {
      "id": "92f999c4",
      "cell_type": "code",
      "source": [
        "import json, nibabel as nib\n",
        "\n",
        "DS_ROOT = Path(os.environ[\"nnUNet_raw\"]) / DATASET_DIR\n",
        "assert DS_ROOT.exists(), f\"Dataset not found at {DS_ROOT}\"\n",
        "\n",
        "for folder in [\"imagesTr\",\"labelsTr\"]:\n",
        "    p = DS_ROOT/folder\n",
        "    assert p.exists() and p.is_dir(), f\"Missing folder: {p}\"\n",
        "imagesTs_exists = (DS_ROOT/\"imagesTs\").exists() and (DS_ROOT/\"imagesTs\").is_dir()\n",
        "print(\"imagesTs:\", \"OK\" if imagesTs_exists else \"Not found (you can still train)\")\n",
        "\n",
        "dj_path = DS_ROOT/\"dataset.json\"\n",
        "assert dj_path.exists(), \"dataset.json is missing!\"\n",
        "with open(dj_path) as f:\n",
        "    dj = json.load(f)\n",
        "\n",
        "print(\"channel_names:\", dj.get(\"channel_names\"))\n",
        "print(\"labels:\", dj.get(\"labels\"))\n",
        "print(\"file_ending:\", dj.get(\"file_ending\"))\n",
        "assert dj.get(\"file_ending\") in [\".nii\", \".nii.gz\"], \"file_ending must be .nii or .nii.gz\"\n",
        "\n",
        "# Check 1:1 pairing for first 5\n",
        "labels = sorted((DS_ROOT/\"labelsTr\").glob(\"*.nii*\"))\n",
        "missing = []\n",
        "for lbl in labels:\n",
        "    stem = lbl.name.replace(\".nii.gz\",\"\").replace(\".nii\",\"\")\n",
        "    img0 = DS_ROOT/\"imagesTr\"/f\"{stem}_0000.nii\"\n",
        "    img1 = DS_ROOT/\"imagesTr\"/f\"{stem}_0000.nii.gz\"\n",
        "    if not img0.exists() and not img1.exists():\n",
        "        missing.append(lbl.name)\n",
        "assert not missing, f\"Missing images for labels: {missing[:10]}\"\n",
        "\n",
        "# Geometry spot-check\n",
        "checked = 0\n",
        "for lbl in labels[:5]:\n",
        "    stem = lbl.name.replace(\".nii.gz\",\"\").replace(\".nii\",\"\")\n",
        "    img_path = DS_ROOT/\"imagesTr\"/f\"{stem}_0000.nii\"\n",
        "    if not img_path.exists():\n",
        "        img_path = DS_ROOT/\"imagesTr\"/f\"{stem}_0000.nii.gz\"\n",
        "    img = nib.load(str(img_path))\n",
        "    seg = nib.load(str(lbl))\n",
        "    assert img.shape == seg.shape, f\"Shape mismatch for {stem}: {img.shape} vs {seg.shape}\"\n",
        "    checked += 1\n",
        "\n",
        "print(f\"✅ Preflight OK. Checked {checked} sample pairs.\")\n",
        "print(\"imagesTr count:\", len(list((DS_ROOT/'imagesTr').glob('*.nii*'))))\n",
        "print(\"labelsTr count:\", len(list((DS_ROOT/'labelsTr').glob('*.nii*'))))\n",
        "if imagesTs_exists:\n",
        "    print(\"imagesTs count:\", len(list((DS_ROOT/'imagesTs').glob('*.nii*'))))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T12:04:24.440186Z",
          "iopub.execute_input": "2025-10-17T12:04:24.440843Z",
          "iopub.status.idle": "2025-10-17T12:04:24.463952Z",
          "shell.execute_reply.started": "2025-10-17T12:04:24.440819Z",
          "shell.execute_reply": "2025-10-17T12:04:24.463100Z"
        },
        "id": "92f999c4",
        "outputId": "e0908c00-278e-4c35-9424-457aaa873aee"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "imagesTs: OK\nchannel_names: {'0': 'FLAIR'}\nlabels: {'background': 0, 'lesion': 1}\nfile_ending: .nii\n✅ Preflight OK. Checked 5 sample pairs.\nimagesTr count: 57\nlabelsTr count: 57\nimagesTs count: 28\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Plan & preprocess (only if needed)"
      ],
      "metadata": {
        "id": "xlXrvy7G1ixa"
      },
      "id": "xlXrvy7G1ixa"
    },
    {
      "id": "3422587a",
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "need_replan = FORCE_REPLAN or not (Path(os.environ[\"nnUNet_preprocessed\"]) / DATASET_DIR).exists()\n",
        "\n",
        "if need_replan:\n",
        "    print(\"Running plan_and_preprocess...\")\n",
        "    !nnUNetv2_plan_and_preprocess -d \"$(printf '%03d' $DATASET_ID)\" --verify_dataset_integrity\n",
        "else:\n",
        "    print(\"Skipping plan_and_preprocess (preprocessed data already present).\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T12:04:28.422551Z",
          "iopub.execute_input": "2025-10-17T12:04:28.423064Z",
          "iopub.status.idle": "2025-10-17T12:04:28.428606Z",
          "shell.execute_reply.started": "2025-10-17T12:04:28.423041Z",
          "shell.execute_reply": "2025-10-17T12:04:28.427705Z"
        },
        "id": "3422587a",
        "outputId": "99a68d01-f579-4e44-e47e-c86473fa5a5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Skipping plan_and_preprocess (preprocessed data already present).\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "id": "9fa43977-51f5-4f00-9f78-bb55c93e0faf",
      "cell_type": "code",
      "source": [
        "# Make sure every child process sees these (works in Kaggle/Colab)\n",
        "%env NNUNET_USE_COMPILE=0\n",
        "%env TORCHDYNAMO_DISABLE=1\n",
        "%env TORCH_COMPILE_DISABLE=1   # extra belt-and-suspenders\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T12:04:30.417523Z",
          "iopub.execute_input": "2025-10-17T12:04:30.418262Z",
          "iopub.status.idle": "2025-10-17T12:04:30.423648Z",
          "shell.execute_reply.started": "2025-10-17T12:04:30.418234Z",
          "shell.execute_reply": "2025-10-17T12:04:30.422710Z"
        },
        "id": "9fa43977-51f5-4f00-9f78-bb55c93e0faf",
        "outputId": "96647990-fe80-40e4-889f-6f24c375cfa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "env: NNUNET_USE_COMPILE=0\nenv: TORCHDYNAMO_DISABLE=1\nenv: TORCH_COMPILE_DISABLE=1   # extra belt-and-suspenders\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) Train (choose one)"
      ],
      "metadata": {
        "id": "QSUzBeL21l0g"
      },
      "id": "QSUzBeL21l0g"
    },
    {
      "id": "1efbe76d",
      "cell_type": "code",
      "source": [
        "# Option A: Train ALL folds\n",
        "!nnUNetv2_train \"$(printf '%03d' $DATASET_ID)\" 3d_fullres all\n",
        "\n",
        "# Option B: Train single fold\n",
        "FOLD=0\n",
        "# !nnUNetv2_train \"$(printf '%03d' $DATASET_ID)\" 3d_fullres $FOLD"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T12:04:32.590516Z",
          "iopub.execute_input": "2025-10-17T12:04:32.591185Z",
          "execution_failed": "2025-10-17T20:30:25.005Z"
        },
        "id": "1efbe76d",
        "outputId": "41adf77d-5795-440a-f163-eb9c7e7b58da"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\n############################\nINFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n############################\n\nUsing device: cuda:0\n\n#######################################################################\nPlease cite the following paper when using nnU-Net:\nIsensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n#######################################################################\n\n2025-10-17 12:04:44.944687: Using torch.compile...\n2025-10-17 12:04:44.960479: do_dummy_2d_data_aug: False\nusing pin_memory on device 0\nusing pin_memory on device 0\n\nThis is the configuration used by this training:\nConfiguration name: 3d_fullres\n {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [160, 160, 96], 'median_image_size_in_voxels': [255.0, 255.0, 160.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 1]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} \n\nThese are the global plan.json settings:\n {'dataset_name': 'Dataset002_BonnFCD', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [255, 255, 160], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 610.9953002929688, 'mean': 136.66336059570312, 'median': 121.00050354003906, 'min': 0.0, 'percentile_00_5': 54.99937438964844, 'percentile_99_5': 398.0054626464844, 'std': 62.28651428222656}}} \n\n2025-10-17 12:04:47.254878: Unable to plot network architecture: nnUNet_compile is enabled!\n2025-10-17 12:04:47.276365: \n2025-10-17 12:04:47.277025: Epoch 0\n2025-10-17 12:04:47.277583: Current learning rate: 0.01\n2025-10-17 12:14:26.743015: train_loss 0.0375\n2025-10-17 12:14:26.743278: val_loss -0.0011\n2025-10-17 12:14:26.743384: Pseudo dice [0.0]\n2025-10-17 12:14:26.743552: Epoch time: 579.47 s\n2025-10-17 12:14:26.743800: Yayy! New best EMA pseudo Dice: 0.0\n2025-10-17 12:14:28.663423: \n2025-10-17 12:14:28.663650: Epoch 1\n2025-10-17 12:14:28.663833: Current learning rate: 0.00999\n2025-10-17 12:21:39.170788: train_loss -0.0079\n2025-10-17 12:21:39.171076: val_loss -0.0124\n2025-10-17 12:21:39.171190: Pseudo dice [0.0]\n2025-10-17 12:21:39.171285: Epoch time: 430.51 s\n2025-10-17 12:21:40.815003: \n2025-10-17 12:21:40.815285: Epoch 2\n2025-10-17 12:21:40.815615: Current learning rate: 0.00998\n2025-10-17 12:28:51.323396: train_loss -0.0194\n2025-10-17 12:28:51.323778: val_loss -0.0548\n2025-10-17 12:28:51.323966: Pseudo dice [0.0]\n2025-10-17 12:28:51.324142: Epoch time: 430.51 s\n2025-10-17 12:28:53.401543: \n2025-10-17 12:28:53.401758: Epoch 3\n2025-10-17 12:28:53.402002: Current learning rate: 0.00997\n2025-10-17 12:36:03.901641: train_loss -0.0602\n2025-10-17 12:36:03.901952: val_loss -0.0635\n2025-10-17 12:36:03.902158: Pseudo dice [0.0]\n2025-10-17 12:36:03.902260: Epoch time: 430.5 s\n2025-10-17 12:36:05.639839: \n2025-10-17 12:36:05.640048: Epoch 4\n2025-10-17 12:36:05.640210: Current learning rate: 0.00996\n2025-10-17 12:43:16.222528: train_loss -0.0764\n2025-10-17 12:43:16.222808: val_loss -0.0772\n2025-10-17 12:43:16.222974: Pseudo dice [0.0]\n2025-10-17 12:43:16.223135: Epoch time: 430.58 s\n2025-10-17 12:43:18.000860: \n2025-10-17 12:43:18.001222: Epoch 5\n2025-10-17 12:43:18.001377: Current learning rate: 0.00995\n2025-10-17 12:50:28.669536: train_loss -0.0901\n2025-10-17 12:50:28.669891: val_loss -0.0697\n2025-10-17 12:50:28.670156: Pseudo dice [0.0]\n2025-10-17 12:50:28.670302: Epoch time: 430.67 s\n2025-10-17 12:50:30.483968: \n2025-10-17 12:50:30.484177: Epoch 6\n2025-10-17 12:50:30.484351: Current learning rate: 0.00995\n2025-10-17 12:57:41.163756: train_loss -0.0882\n2025-10-17 12:57:41.164123: val_loss -0.1011\n2025-10-17 12:57:41.164379: Pseudo dice [0.0]\n2025-10-17 12:57:41.164547: Epoch time: 430.68 s\n2025-10-17 12:57:42.878079: \n2025-10-17 12:57:42.878410: Epoch 7\n2025-10-17 12:57:42.878586: Current learning rate: 0.00994\n2025-10-17 13:04:53.675442: train_loss -0.0992\n2025-10-17 13:04:53.675731: val_loss -0.0873\n2025-10-17 13:04:53.675937: Pseudo dice [0.0]\n2025-10-17 13:04:53.676124: Epoch time: 430.8 s\n2025-10-17 13:04:55.531267: \n2025-10-17 13:04:55.531451: Epoch 8\n2025-10-17 13:04:55.531614: Current learning rate: 0.00993\n2025-10-17 13:12:06.350669: train_loss -0.0965\n2025-10-17 13:12:06.351013: val_loss -0.0998\n2025-10-17 13:12:06.351167: Pseudo dice [0.0001]\n2025-10-17 13:12:06.351322: Epoch time: 430.82 s\n2025-10-17 13:12:06.351437: Yayy! New best EMA pseudo Dice: 0.0\n2025-10-17 13:12:08.902038: \n2025-10-17 13:12:08.902354: Epoch 9\n2025-10-17 13:12:08.902514: Current learning rate: 0.00992\n2025-10-17 13:19:19.717077: train_loss -0.1063\n2025-10-17 13:19:19.717457: val_loss -0.124\n2025-10-17 13:19:19.717600: Pseudo dice [0.0]\n2025-10-17 13:19:19.717732: Epoch time: 430.82 s\n2025-10-17 13:19:21.642483: \n2025-10-17 13:19:21.642690: Epoch 10\n2025-10-17 13:19:21.642867: Current learning rate: 0.00991\n2025-10-17 13:26:32.464850: train_loss -0.1151\n2025-10-17 13:26:32.465199: val_loss -0.1284\n2025-10-17 13:26:32.465354: Pseudo dice [0.0018]\n2025-10-17 13:26:32.465515: Epoch time: 430.82 s\n2025-10-17 13:26:32.465686: Yayy! New best EMA pseudo Dice: 0.0002\n2025-10-17 13:26:34.977662: \n2025-10-17 13:26:34.977846: Epoch 11\n2025-10-17 13:26:34.978025: Current learning rate: 0.0099\n2025-10-17 13:33:45.820502: train_loss -0.1375\n2025-10-17 13:33:45.820801: val_loss -0.2323\n2025-10-17 13:33:45.820995: Pseudo dice [0.3879]\n2025-10-17 13:33:45.821125: Epoch time: 430.84 s\n2025-10-17 13:33:45.821333: Yayy! New best EMA pseudo Dice: 0.039\n2025-10-17 13:33:48.778653: \n2025-10-17 13:33:48.779005: Epoch 12\n2025-10-17 13:33:48.779190: Current learning rate: 0.00989\n2025-10-17 13:40:59.665956: train_loss -0.2209\n2025-10-17 13:40:59.666309: val_loss -0.237\n2025-10-17 13:40:59.666456: Pseudo dice [0.3533]\n2025-10-17 13:40:59.666604: Epoch time: 430.89 s\n2025-10-17 13:40:59.666730: Yayy! New best EMA pseudo Dice: 0.0704\n2025-10-17 13:41:02.167762: \n2025-10-17 13:41:02.168144: Epoch 13\n2025-10-17 13:41:02.168315: Current learning rate: 0.00988\n2025-10-17 13:48:13.013883: train_loss -0.2342\n2025-10-17 13:48:13.014199: val_loss -0.2129\n2025-10-17 13:48:13.014339: Pseudo dice [0.2995]\n2025-10-17 13:48:13.014525: Epoch time: 430.85 s\n2025-10-17 13:48:13.014680: Yayy! New best EMA pseudo Dice: 0.0933\n2025-10-17 13:48:15.489188: \n2025-10-17 13:48:15.489452: Epoch 14\n2025-10-17 13:48:15.489602: Current learning rate: 0.00987\n2025-10-17 13:55:26.360833: train_loss -0.2319\n2025-10-17 13:55:26.361145: val_loss -0.2272\n2025-10-17 13:55:26.361282: Pseudo dice [0.333]\n2025-10-17 13:55:26.361401: Epoch time: 430.87 s\n2025-10-17 13:55:26.361530: Yayy! New best EMA pseudo Dice: 0.1173\n2025-10-17 13:55:28.840742: \n2025-10-17 13:55:28.841121: Epoch 15\n2025-10-17 13:55:28.841305: Current learning rate: 0.00986\n2025-10-17 14:02:39.718054: train_loss -0.2553\n2025-10-17 14:02:39.718494: val_loss -0.2902\n2025-10-17 14:02:39.718660: Pseudo dice [0.4421]\n2025-10-17 14:02:39.718876: Epoch time: 430.88 s\n2025-10-17 14:02:39.719038: Yayy! New best EMA pseudo Dice: 0.1498\n2025-10-17 14:02:42.364065: \n2025-10-17 14:02:42.364448: Epoch 16\n2025-10-17 14:02:42.364599: Current learning rate: 0.00986\n2025-10-17 14:09:53.130316: train_loss -0.2597\n2025-10-17 14:09:53.130677: val_loss -0.2673\n2025-10-17 14:09:53.130811: Pseudo dice [0.4245]\n2025-10-17 14:09:53.130961: Epoch time: 430.77 s\n2025-10-17 14:09:53.131074: Yayy! New best EMA pseudo Dice: 0.1772\n2025-10-17 14:09:55.669922: \n2025-10-17 14:09:55.670133: Epoch 17\n2025-10-17 14:09:55.670303: Current learning rate: 0.00985\n2025-10-17 14:17:06.480939: train_loss -0.248\n2025-10-17 14:17:06.481267: val_loss -0.2765\n2025-10-17 14:17:06.481367: Pseudo dice [0.3816]\n2025-10-17 14:17:06.481500: Epoch time: 430.81 s\n2025-10-17 14:17:06.481822: Yayy! New best EMA pseudo Dice: 0.1977\n2025-10-17 14:17:09.081318: \n2025-10-17 14:17:09.081658: Epoch 18\n2025-10-17 14:17:09.081836: Current learning rate: 0.00984\n2025-10-17 14:24:19.881141: train_loss -0.2961\n2025-10-17 14:24:19.881444: val_loss -0.2783\n2025-10-17 14:24:19.881599: Pseudo dice [0.4182]\n2025-10-17 14:24:19.881749: Epoch time: 430.8 s\n2025-10-17 14:24:19.881853: Yayy! New best EMA pseudo Dice: 0.2197\n2025-10-17 14:24:22.547379: \n2025-10-17 14:24:22.547702: Epoch 19\n2025-10-17 14:24:22.547858: Current learning rate: 0.00983\n2025-10-17 14:31:33.395922: train_loss -0.2801\n2025-10-17 14:31:33.396343: val_loss -0.3303\n2025-10-17 14:31:33.396455: Pseudo dice [0.445]\n2025-10-17 14:31:33.396568: Epoch time: 430.85 s\n2025-10-17 14:31:33.396658: Yayy! New best EMA pseudo Dice: 0.2422\n2025-10-17 14:31:36.287850: \n2025-10-17 14:31:36.288054: Epoch 20\n2025-10-17 14:31:36.288222: Current learning rate: 0.00982\n2025-10-17 14:38:47.181558: train_loss -0.2922\n2025-10-17 14:38:47.181884: val_loss -0.3362\n2025-10-17 14:38:47.182142: Pseudo dice [0.4882]\n2025-10-17 14:38:47.182304: Epoch time: 430.89 s\n2025-10-17 14:38:47.182428: Yayy! New best EMA pseudo Dice: 0.2668\n2025-10-17 14:38:49.858029: \n2025-10-17 14:38:49.858277: Epoch 21\n2025-10-17 14:38:49.858427: Current learning rate: 0.00981\n2025-10-17 14:46:00.693386: train_loss -0.3131\n2025-10-17 14:46:00.693788: val_loss -0.3352\n2025-10-17 14:46:00.693949: Pseudo dice [0.457]\n2025-10-17 14:46:00.694079: Epoch time: 430.84 s\n2025-10-17 14:46:00.694217: Yayy! New best EMA pseudo Dice: 0.2859\n2025-10-17 14:46:03.276034: \n2025-10-17 14:46:03.276454: Epoch 22\n2025-10-17 14:46:03.276709: Current learning rate: 0.0098\n2025-10-17 14:53:14.085307: train_loss -0.2863\n2025-10-17 14:53:14.085691: val_loss -0.2901\n2025-10-17 14:53:14.085948: Pseudo dice [0.4143]\n2025-10-17 14:53:14.086136: Epoch time: 430.81 s\n2025-10-17 14:53:14.086262: Yayy! New best EMA pseudo Dice: 0.2987\n2025-10-17 14:53:16.680630: \n2025-10-17 14:53:16.681017: Epoch 23\n2025-10-17 14:53:16.681203: Current learning rate: 0.00979\n2025-10-17 15:00:27.557965: train_loss -0.3319\n2025-10-17 15:00:27.558292: val_loss -0.3127\n2025-10-17 15:00:27.558451: Pseudo dice [0.4993]\n2025-10-17 15:00:27.558613: Epoch time: 430.88 s\n2025-10-17 15:00:27.558731: Yayy! New best EMA pseudo Dice: 0.3188\n2025-10-17 15:00:30.063156: \n2025-10-17 15:00:30.063496: Epoch 24\n2025-10-17 15:00:30.063669: Current learning rate: 0.00978\n2025-10-17 15:07:40.877863: train_loss -0.3169\n2025-10-17 15:07:40.878249: val_loss -0.3267\n2025-10-17 15:07:40.878400: Pseudo dice [0.4585]\n2025-10-17 15:07:40.878551: Epoch time: 430.82 s\n2025-10-17 15:07:40.878676: Yayy! New best EMA pseudo Dice: 0.3327\n2025-10-17 15:07:43.475431: \n2025-10-17 15:07:43.475762: Epoch 25\n2025-10-17 15:07:43.475968: Current learning rate: 0.00977\n2025-10-17 15:14:54.301245: train_loss -0.3094\n2025-10-17 15:14:54.301603: val_loss -0.322\n2025-10-17 15:14:54.301756: Pseudo dice [0.4665]\n2025-10-17 15:14:54.301928: Epoch time: 430.83 s\n2025-10-17 15:14:54.302094: Yayy! New best EMA pseudo Dice: 0.3461\n2025-10-17 15:14:56.836992: \n2025-10-17 15:14:56.837189: Epoch 26\n2025-10-17 15:14:56.837368: Current learning rate: 0.00977\n2025-10-17 15:22:07.614658: train_loss -0.317\n2025-10-17 15:22:07.615072: val_loss -0.3453\n2025-10-17 15:22:07.615254: Pseudo dice [0.491]\n2025-10-17 15:22:07.615416: Epoch time: 430.78 s\n2025-10-17 15:22:07.615535: Yayy! New best EMA pseudo Dice: 0.3606\n2025-10-17 15:22:10.049391: \n2025-10-17 15:22:10.049531: Epoch 27\n2025-10-17 15:22:10.049677: Current learning rate: 0.00976\n2025-10-17 15:29:20.620559: train_loss -0.3182\n2025-10-17 15:29:20.620851: val_loss -0.3802\n2025-10-17 15:29:20.621046: Pseudo dice [0.5586]\n2025-10-17 15:29:20.621186: Epoch time: 430.57 s\n2025-10-17 15:29:20.621320: Yayy! New best EMA pseudo Dice: 0.3804\n2025-10-17 15:29:22.963149: \n2025-10-17 15:29:22.963354: Epoch 28\n2025-10-17 15:29:22.963652: Current learning rate: 0.00975\n2025-10-17 15:36:33.667078: train_loss -0.3291\n2025-10-17 15:36:33.667405: val_loss -0.3433\n2025-10-17 15:36:33.667565: Pseudo dice [0.4591]\n2025-10-17 15:36:33.667711: Epoch time: 430.71 s\n2025-10-17 15:36:33.667851: Yayy! New best EMA pseudo Dice: 0.3883\n2025-10-17 15:36:36.530038: \n2025-10-17 15:36:36.530360: Epoch 29\n2025-10-17 15:36:36.530517: Current learning rate: 0.00974\n2025-10-17 15:43:47.296499: train_loss -0.3201\n2025-10-17 15:43:47.296803: val_loss -0.4196\n2025-10-17 15:43:47.297002: Pseudo dice [0.5331]\n2025-10-17 15:43:47.297139: Epoch time: 430.77 s\n2025-10-17 15:43:47.297231: Yayy! New best EMA pseudo Dice: 0.4027\n2025-10-17 15:43:49.788725: \n2025-10-17 15:43:49.789102: Epoch 30\n2025-10-17 15:43:49.789289: Current learning rate: 0.00973\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}